# Ocena ZÅ‚oÅ¼onoÅ›ci AlgorytmÃ³w â€” Kompletna Notatka do Obrony

## 0) Podstawy â€” od zera (dla poczÄ…tkujÄ…cych)

### Co to jest algorytm?

**Algorytm** = krok po kroku instrukcje, jak rozwiÄ…zaÄ‡ problem.

**PrzykÅ‚ad z Å¼ycia:**
- **Problem:** Jak ugotowaÄ‡ jajko?
- **Algorytm:**
  1. Wlej wodÄ™ do garnka
  2. Zagotuj wodÄ™
  3. WÅ‚Ã³Å¼ jajko
  4. Gotuj 5 minut
  5. Wyjmij jajko

**W programowaniu:**
- **Problem:** ZnajdÅº najwiÄ™kszÄ… liczbÄ™ w tablicy
- **Algorytm:**
  1. WeÅº pierwszÄ… liczbÄ™ jako maksimum
  2. Dla kaÅ¼dej kolejnej liczby:
     - JeÅ›li jest wiÄ™ksza niÅ¼ maksimum â†’ ustaw jako nowe maksimum
  3. ZwrÃ³Ä‡ maksimum

### Co to jest zÅ‚oÅ¼onoÅ›Ä‡ algorytmu?

**ZÅ‚oÅ¼onoÅ›Ä‡** = jak szybko roÅ›nie czas wykonania lub pamiÄ™Ä‡, gdy zwiÄ™kszamy rozmiar danych.

**PrzykÅ‚ad intuicyjny:**
- **Problem:** ZnajdÅº numer telefonu w ksiÄ…Å¼ce telefonicznej
- **Rozmiar danych:** n = liczba osÃ³b w ksiÄ…Å¼ce
- **Pytanie:** Jak szybko roÅ›nie czas wyszukiwania, gdy ksiÄ…Å¼ka ma wiÄ™cej osÃ³b?

**Dwa algorytmy:**

**Algorytm 1: Wyszukiwanie liniowe**
- Sprawdzaj od poczÄ…tku do koÅ„ca, jedna po drugiej
- W najgorszym przypadku: sprawdzisz wszystkie n osÃ³b
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(n) â€” czas roÅ›nie liniowo

**Algorytm 2: Wyszukiwanie binarne**
- OtwÃ³rz ksiÄ…Å¼kÄ™ w poÅ‚owie
- JeÅ›li szukane nazwisko jest wczeÅ›niej â†’ szukaj w pierwszej poÅ‚owie
- JeÅ›li pÃ³Åºniej â†’ szukaj w drugiej poÅ‚owie
- Powtarzaj, aÅ¼ znajdziesz
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(log n) â€” czas roÅ›nie logarytmicznie (duÅ¼o szybciej!)

**PorÃ³wnanie dla n = 1 000 000:**
- Algorytm 1: ~1 000 000 sprawdzeÅ„ (w najgorszym przypadku)
- Algorytm 2: ~20 sprawdzeÅ„ (logâ‚‚(1 000 000) â‰ˆ 20)

**RÃ³Å¼nica jest ogromna!**

### Dlaczego zÅ‚oÅ¼onoÅ›Ä‡ jest waÅ¼na?

**Problem:** Komputer moÅ¼e wykonaÄ‡ ~1 miliard operacji na sekundÄ™.

**Scenariusz:** Masz tablicÄ™ z 1 miliardem liczb i chcesz je posortowaÄ‡.

**Algorytm O(nÂ²):**
- Operacje: nÂ² = (10â¹)Â² = 10Â¹â¸ operacji
- Czas: 10Â¹â¸ / 10â¹ = 10â¹ sekund = **~31 lat!** ğŸ˜±

**Algorytm O(n log n):**
- Operacje: n log n = 10â¹ Ã— log(10â¹) â‰ˆ 10â¹ Ã— 30 = 3 Ã— 10Â¹â° operacji
- Czas: 3 Ã— 10Â¹â° / 10â¹ = 30 sekund âœ“

**Wniosek:** WybÃ³r algorytmu ma ogromne znaczenie!

### Co oznacza "n"?

**n** = rozmiar danych wejÅ›ciowych (liczba elementÃ³w do przetworzenia).

**PrzykÅ‚ady:**
- Tablica z liczbami: n = dÅ‚ugoÅ›Ä‡ tablicy
- Lista studentÃ³w: n = liczba studentÃ³w
- Graf: n = liczba wÄ™zÅ‚Ã³w
- Macierz: n = liczba wierszy (lub kolumn)

**PrzykÅ‚ad:**
```java
int[] array = {1, 5, 3, 9, 2};  // n = 5
for (int i = 0; i < array.length; i++) {  // n iteracji
    System.out.println(array[i]);
}
```

### Co to jest operacja podstawowa?

**Operacja podstawowa** = pojedyncza, prosta operacja, ktÃ³ra zajmuje staÅ‚y czas.

**PrzykÅ‚ady operacji podstawowych:**
- Przypisanie: `x = 5`
- PorÃ³wnanie: `if (a > b)`
- Arytmetyka: `a + b`, `a * b`
- DostÄ™p do tablicy: `array[i]`
- WywoÅ‚anie funkcji: `function()`

**PrzykÅ‚ad zliczania operacji:**
```java
int sum = 0;                    // 1 operacja (przypisanie)
for (int i = 0; i < n; i++) {   // n iteracji
    sum += array[i];            // 2 operacje w kaÅ¼dej iteracji (dostÄ™p + dodawanie)
}
return sum;                     // 1 operacja (return)

// Razem: 1 + n * 2 + 1 = 2n + 2 operacji
```

### Co to jest czas wykonania?

**Czas wykonania T(n)** = liczba operacji podstawowych dla danych rozmiaru n.

**PrzykÅ‚ad:**
- Algorytm wykonuje 3n + 5 operacji dla danych rozmiaru n
- T(n) = 3n + 5
- Dla n = 100: T(100) = 3 Ã— 100 + 5 = 305 operacji

**Uwaga:** Nie mierzymy czasu w sekundach, tylko w liczbie operacji!
- RÃ³Å¼ne komputery majÄ… rÃ³Å¼nÄ… prÄ™dkoÅ›Ä‡
- Liczba operacji jest uniwersalna

### Co to jest asymptotyczna analiza?

**Asymptotyczna analiza** = analiza zachowania algorytmu dla **bardzo duÅ¼ych** n (n â†’ âˆ).

**Dlaczego?**
- Dla maÅ‚ych n rÃ³Å¼nice sÄ… nieistotne
- Dla duÅ¼ych n rÃ³Å¼nice sÄ… ogromne
- Chcemy wiedzieÄ‡, jak algorytm zachowa siÄ™ w praktyce

**PrzykÅ‚ad:**
- T(n) = 3n + 5
- Dla maÅ‚ych n: staÅ‚a 5 jest waÅ¼na
- Dla duÅ¼ych n: 3n dominuje, staÅ‚a 5 jest nieistotna
- **Asymptotycznie:** T(n) â‰ˆ 3n = O(n)

---

## 1) Wprowadzenie â€” po co oceniaÄ‡ zÅ‚oÅ¼onoÅ›Ä‡?

### Dlaczego zÅ‚oÅ¼onoÅ›Ä‡ algorytmÃ³w jest waÅ¼na?

**ZÅ‚oÅ¼onoÅ›Ä‡ algorytmu** mÃ³wi nam, jak szybko roÅ›nie czas wykonania lub zuÅ¼ycie pamiÄ™ci wraz ze wzrostem rozmiaru danych wejÅ›ciowych.

### Podstawowe pytania:
- Czy algorytm bÄ™dzie dziaÅ‚aÅ‚ szybko na duÅ¼ych danych?
- Ile pamiÄ™ci bÄ™dzie potrzebowaÅ‚?
- Czy istnieje lepszy algorytm?
- Czy rozwiÄ…zanie jest praktyczne dla danych problemÃ³w?

### PrzykÅ‚ad problemu â€” szczegÃ³Å‚owa analiza:

**Scenariusz:** Masz tablicÄ™ z 1000 liczb i chcesz znaleÅºÄ‡ najwiÄ™kszÄ….

**Algorytm A: Wyszukiwanie liniowe â€” O(n)**
```java
int findMax(int[] array) {
    int max = array[0];                    // 1 operacja
    for (int i = 1; i < array.length; i++) {  // n-1 iteracji
        if (array[i] > max) {              // 1 porÃ³wnanie
            max = array[i];                // 1 przypisanie (czasami)
        }
    }
    return max;                            // 1 operacja
}
```

**Analiza:**
- Operacje: 1 + (n-1) Ã— 2 + 1 = 2n operacji
- Dla n = 1000: 2000 operacji
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(n) â€” czas roÅ›nie liniowo

**Algorytm B: Sortowanie + wybÃ³r â€” O(nÂ²)**
```java
int findMaxBad(int[] array) {
    // Najpierw sortuj (bubble sort - O(nÂ²))
    for (int i = 0; i < array.length; i++) {        // n iteracji
        for (int j = 0; j < array.length - 1; j++) { // n iteracji
            if (array[j] > array[j+1]) {
                swap(array, j, j+1);
            }
        }
    }
    return array[array.length - 1];  // Ostatni element
}
```

**Analiza:**
- Operacje: n Ã— n = nÂ² operacji
- Dla n = 1000: 1 000 000 operacji
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(nÂ²) â€” czas roÅ›nie kwadratowo

**PorÃ³wnanie:**
- n = 1000: Algorytm A = 2000 operacji, Algorytm B = 1 000 000 operacji
- **RÃ³Å¼nica:** 500x wolniejszy!

**Dla n = 1 000 000:**
- Algorytm A: 2 000 000 operacji (~0.002 sekundy)
- Algorytm B: 1 000 000 000 000 operacji (~1000 sekund = ~16 minut!)

**RÃ³Å¼nica jest ogromna!**

### Cel analizy zÅ‚oÅ¼onoÅ›ci:
> **PrzewidzieÄ‡ zachowanie algorytmu na duÅ¼ych danych i porÃ³wnaÄ‡ rÃ³Å¼ne algorytmy.**

---

## 2) Notacja asymptotyczna â€” Big O, Omega, Theta

### Notacja Big O (O) â€” gÃ³rna granica

**Definicja:**
Algorytm ma zÅ‚oÅ¼onoÅ›Ä‡ **O(f(n))**, jeÅ›li istniejÄ… staÅ‚e c > 0 i nâ‚€ takie, Å¼e dla wszystkich n â‰¥ nâ‚€:
T(n) â‰¤ c * f(n)

**Intuicyjnie:** "Algorytm nie bÄ™dzie gorszy niÅ¼ f(n)"

**PrzykÅ‚ad:**
JeÅ›li T(n) = 3n + 5, to T(n) = O(n), bo:
3n + 5 â‰¤ 4n dla n â‰¥ 5

### Notacja Big Omega (Î©) â€” dolna granica

**Definicja:**
Algorytm ma zÅ‚oÅ¼onoÅ›Ä‡ **Î©(f(n))**, jeÅ›li istniejÄ… staÅ‚e c > 0 i nâ‚€ takie, Å¼e dla wszystkich n â‰¥ nâ‚€:
T(n) â‰¥ c * f(n)

**Intuicyjnie:** "Algorytm nie bÄ™dzie lepszy niÅ¼ f(n)"

**PrzykÅ‚ad:**
JeÅ›li T(n) = 3n + 5, to T(n) = Î©(n), bo:
3n + 5 â‰¥ n dla n â‰¥ 1

### Notacja Big Theta (Î˜) â€” dokÅ‚adna granica

**Definicja:**
Algorytm ma zÅ‚oÅ¼onoÅ›Ä‡ **Î˜(f(n))**, jeÅ›li:
- T(n) = O(f(n)) ORAZ
- T(n) = Î©(f(n))

**Intuicyjnie:** "Algorytm ma dokÅ‚adnie zÅ‚oÅ¼onoÅ›Ä‡ f(n)"

**PrzykÅ‚ad:**
JeÅ›li T(n) = 3n + 5, to T(n) = Î˜(n)

### RÃ³Å¼nice miÄ™dzy notacjami:

| Notacja | Znaczenie | UÅ¼ycie |
|---------|-----------|--------|
| **O(f(n))** | Najgorszy przypadek (gÃ³rna granica) | "Algorytm nie gorszy niÅ¼..." |
| **Î©(f(n))** | Najlepszy przypadek (dolna granica) | "Algorytm nie lepszy niÅ¼..." |
| **Î˜(f(n))** | DokÅ‚adna zÅ‚oÅ¼onoÅ›Ä‡ (gdy O = Î©) | "Algorytm ma dokÅ‚adnie..." |

### W praktyce:
- **Big O** jest najczÄ™Å›ciej uÅ¼ywana (analiza najgorszego przypadku)
- **Theta** gdy chcemy powiedzieÄ‡ o dokÅ‚adnej zÅ‚oÅ¼onoÅ›ci
- **Omega** rzadziej uÅ¼ywana (zwykle do pokazania, Å¼e nie da siÄ™ lepiej)

---

## 3) NajczÄ™stsze klasy zÅ‚oÅ¼onoÅ›ci

### Hierarchia zÅ‚oÅ¼onoÅ›ci (od najlepszej do najgorszej):

```
O(1) < O(log n) < O(âˆšn) < O(n) < O(n log n) < O(nÂ²) < O(nÂ³) < O(2^n) < O(n!)
```

### O(1) â€” zÅ‚oÅ¼onoÅ›Ä‡ staÅ‚a â€” szczegÃ³Å‚owo

**Charakterystyka:**
- Czas wykonania **nie zaleÅ¼y** od rozmiaru danych
- Najlepsza moÅ¼liwa zÅ‚oÅ¼onoÅ›Ä‡
- Operacja zawsze trwa tyle samo, niezaleÅ¼nie od n

**Intuicja:** To jak otwarcie drzwi â€” zawsze zajmuje tyle samo czasu, niezaleÅ¼nie od tego, ile osÃ³b jest w pokoju.

**PrzykÅ‚ady szczegÃ³Å‚owe:**

**PrzykÅ‚ad 1: DostÄ™p do elementu tablicy**
```java
int getElement(int[] array, int index) {
    return array[index];  // 1 operacja - zawsze
}
```

**Analiza:**
- Operacje: 1 (dostÄ™p do tablicy)
- Dla n = 10: 1 operacja
- Dla n = 1000: 1 operacja
- Dla n = 1 000 000: 1 operacja
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(1) â€” staÅ‚a

**Dlaczego O(1)?**
- Komputer wie dokÅ‚adnie, gdzie w pamiÄ™ci jest element (adres = poczÄ…tek + indeks Ã— rozmiar)
- Nie musi przeszukiwaÄ‡ â€” idzie bezpoÅ›rednio

**PrzykÅ‚ad 2: Dodanie na koniec ArrayList (amortyzowana)**
```java
ArrayList<Integer> list = new ArrayList<>();
list.add(5);  // O(1) amortyzowana
```

**Analiza:**
- W wiÄ™kszoÅ›ci przypadkÃ³w: O(1) â€” dodaje na koniec
- Czasami: O(n) â€” gdy trzeba powiÄ™kszyÄ‡ tablicÄ™ (ale rzadko)
- **Amortyzowana zÅ‚oÅ¼onoÅ›Ä‡:** O(1)

**PrzykÅ‚ad 3: Operacje na HashMap (idealny przypadek)**
```java
HashMap<String, Integer> map = new HashMap<>();
map.put("key", 5);     // O(1) Å›rednio
map.get("key");        // O(1) Å›rednio
```

**Analiza:**
- Hash table oblicza hash klucza â†’ idzie bezpoÅ›rednio do odpowiedniego miejsca
- W idealnym przypadku: O(1)
- W najgorszym (wszystkie klucze majÄ… ten sam hash): O(n)

**PrzykÅ‚ad 4: Operacje matematyczne**
```java
int add(int a, int b) {
    return a + b;  // O(1) - zawsze 1 operacja
}

int multiply(int a, int b) {
    return a * b;  // O(1) - zawsze 1 operacja
}
```

**Wykres:** Linia pozioma (nie roÅ›nie)
```
Czas
  |
  |â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (staÅ‚y)
  |
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ n
```

**Tabela porÃ³wnawcza:**
| n | Operacje O(1) |
|---|---------------|
| 10 | 1 |
| 100 | 1 |
| 1000 | 1 |
| 1 000 000 | 1 |

**Wniosek:** O(1) to najlepsza moÅ¼liwa zÅ‚oÅ¼onoÅ›Ä‡ â€” zawsze szybka!

### O(log n) â€” zÅ‚oÅ¼onoÅ›Ä‡ logarytmiczna â€” szczegÃ³Å‚owo

**Charakterystyka:**
- Czas roÅ›nie **bardzo wolno**
- Podwajanie danych = +1 operacja
- Bardzo dobra zÅ‚oÅ¼onoÅ›Ä‡

**Intuicja:** To jak szukanie sÅ‚owa w sÅ‚owniku â€” za kaÅ¼dym razem eliminujesz poÅ‚owÄ™ moÅ¼liwoÅ›ci.

**PrzykÅ‚ad z Å¼ycia:**
- **Problem:** ZnajdÅº numer telefonu w ksiÄ…Å¼ce telefonicznej (alfabetycznie)
- **Algorytm:** OtwÃ³rz w poÅ‚owie â†’ sprawdÅº â†’ wybierz odpowiedniÄ… poÅ‚owÄ™ â†’ powtarzaj
- **Kroki:** logâ‚‚(n) â€” dla 1 000 000 osÃ³b potrzebujesz ~20 krokÃ³w!

**PrzykÅ‚ad szczegÃ³Å‚owy: Binary Search**

**Kod:**
```java
int binarySearch(int[] array, int target) {
    int left = 0;
    int right = array.length - 1;
    
    while (left <= right) {
        int mid = (left + right) / 2;  // Åšrodek
        
        if (array[mid] == target) {
            return mid;  // Znaleziono!
        }
        
        if (array[mid] < target) {
            left = mid + 1;  // Szukaj w prawej poÅ‚owie
        } else {
            right = mid - 1;  // Szukaj w lewej poÅ‚owie
        }
    }
    
    return -1;  // Nie znaleziono
}
```

**Analiza krok po kroku:**

**PrzykÅ‚ad:** Szukamy 7 w tablicy [1, 3, 5, 7, 9, 11, 13] (n = 7)

**Iteracja 1:**
- left = 0, right = 6
- mid = (0 + 6) / 2 = 3
- array[3] = 7 â†’ znaleziono! âœ“
- **Operacje:** 1 porÃ³wnanie

**Gdyby szukali 9:**

**Iteracja 1:**
- left = 0, right = 6
- mid = 3, array[3] = 7
- 7 < 9 â†’ left = 4 (szukaj w prawej poÅ‚owie)
- **PozostaÅ‚o:** 3 elementy (9, 11, 13)

**Iteracja 2:**
- left = 4, right = 6
- mid = 5, array[5] = 11
- 11 > 9 â†’ right = 4 (szukaj w lewej poÅ‚owie)
- **PozostaÅ‚o:** 1 element (9)

**Iteracja 3:**
- left = 4, right = 4
- mid = 4, array[4] = 9 â†’ znaleziono! âœ“
- **Operacje:** 3 porÃ³wnania

**Analiza matematyczna:**
- Po kaÅ¼dej iteracji obszar przeszukiwania zmniejsza siÄ™ o poÅ‚owÄ™
- n â†’ n/2 â†’ n/4 â†’ n/8 â†’ ... â†’ 1
- Liczba krokÃ³w: logâ‚‚(n)
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(log n)

**Tabela porÃ³wnawcza:**
| n | Operacje O(log n) | PorÃ³wnanie z O(n) |
|---|-------------------|-------------------|
| 10 | ~3 | 10 |
| 100 | ~7 | 100 |
| 1000 | ~10 | 1000 |
| 1 000 000 | ~20 | 1 000 000 |

**Wykres:** RoÅ›nie bardzo wolno, prawie poziomo
```
Czas
  |
  |     â•±
  |    â•±
  |   â•±
  |  â•±
  | â•±
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ n
```

**Ciekawe fakty:**
- logâ‚‚(1 000 000) â‰ˆ 20
- logâ‚‚(1 000 000 000) â‰ˆ 30
- **Podwajanie danych = +1 operacja!**

**Inne przykÅ‚ady O(log n):**
- Operacje na drzewie binarnym (zbalansowanym)
- Wyszukiwanie w posortowanej tablicy
- Operacje na kopcu (heap)

**Wniosek:** O(log n) to bardzo dobra zÅ‚oÅ¼onoÅ›Ä‡ â€” praktycznie staÅ‚a dla duÅ¼ych n!

### O(âˆšn) â€” zÅ‚oÅ¼onoÅ›Ä‡ pierwiastkowa

**Charakterystyka:**
- Åšrednia zÅ‚oÅ¼onoÅ›Ä‡
- Rzadziej spotykana

**PrzykÅ‚ady:**
- Sprawdzanie czy liczba jest pierwsza (naiwna metoda do âˆšn)
- NiektÃ³re algorytmy na grafach

**Kod:**
```java
boolean isPrime(int n) {
    for (int i = 2; i * i <= n; i++) {  // O(âˆšn) iteracji
        if (n % i == 0) return false;
    }
    return true;
}
```

### O(n) â€” zÅ‚oÅ¼onoÅ›Ä‡ liniowa â€” szczegÃ³Å‚owo

**Charakterystyka:**
- Czas roÅ›nie **proporcjonalnie** do rozmiaru danych
- Podwajanie danych = podwÃ³jny czas
- Dobra zÅ‚oÅ¼onoÅ›Ä‡ dla wiÄ™kszoÅ›ci zastosowaÅ„

**Intuicja:** To jak sprawdzanie listy osÃ³b â€” musisz sprawdziÄ‡ kaÅ¼dÄ… osobÄ™, wiÄ™c czas roÅ›nie liniowo z liczbÄ… osÃ³b.

**PrzykÅ‚ady szczegÃ³Å‚owe:**

**PrzykÅ‚ad 1: Znajdowanie maksimum**
```java
int findMax(int[] array) {
    int max = array[0];                    // 1 operacja
    for (int i = 1; i < array.length; i++) {  // n-1 iteracji
        if (array[i] > max) {              // 1 porÃ³wnanie
            max = array[i];                // 1 przypisanie (czasami)
        }
    }
    return max;                            // 1 operacja
}
```

**Analiza:**
- Operacje: 1 + (n-1) Ã— 2 + 1 = 2n operacji
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(n)

**PrzykÅ‚ad 2: Sumowanie elementÃ³w**
```java
int sum(int[] array) {
    int sum = 0;                           // 1 operacja
    for (int i = 0; i < array.length; i++) {  // n iteracji
        sum += array[i];                   // 2 operacje (dostÄ™p + dodawanie)
    }
    return sum;                            // 1 operacja
}
```

**Analiza:**
- Operacje: 1 + n Ã— 2 + 1 = 2n + 2
- UpraszczajÄ…c: O(n)

**PrzykÅ‚ad 3: Wyszukiwanie liniowe**
```java
int linearSearch(int[] array, int target) {
    for (int i = 0; i < array.length; i++) {  // n iteracji
        if (array[i] == target) {          // 1 porÃ³wnanie
            return i;                      // 1 return (czasami)
        }
    }
    return -1;                             // 1 operacja (w najgorszym przypadku)
}
```

**Analiza:**
- Najlepszy przypadek: O(1) â€” element na pierwszej pozycji
- Najgorszy przypadek: O(n) â€” element na koÅ„cu lub brak
- PrzeciÄ™tny przypadek: O(n) â€” element w Å›rodku
- **W praktyce:** O(n) â€” analizujemy najgorszy przypadek

**PrzykÅ‚ad 4: Kopiowanie tablicy**
```java
int[] copyArray(int[] original) {
    int[] copy = new int[original.length];  // 1 operacja (alokacja)
    for (int i = 0; i < original.length; i++) {  // n iteracji
        copy[i] = original[i];              // 2 operacje (dostÄ™p + przypisanie)
    }
    return copy;                            // 1 operacja
}
```

**Analiza:**
- Operacje: 1 + n Ã— 2 + 1 = 2n + 2
- **ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(n)
- **ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(n) â€” nowa tablica

**Tabela porÃ³wnawcza:**
| n | Operacje O(n) | Czas (przy 1 mld op/s) |
|---|---------------|------------------------|
| 10 | 10 | 0.00000001 s |
| 100 | 100 | 0.0000001 s |
| 1000 | 1000 | 0.000001 s |
| 1 000 000 | 1 000 000 | 0.001 s |
| 1 000 000 000 | 1 000 000 000 | 1 s |

**Wykres:** Linia prosta pod kÄ…tem 45Â°
```
Czas
  |
  |    â•±
  |   â•±
  |  â•±
  | â•±
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ n
```

**Wniosek:** O(n) to dobra zÅ‚oÅ¼onoÅ›Ä‡ â€” akceptowalna dla wiÄ™kszoÅ›ci zastosowaÅ„.

### O(n log n) â€” zÅ‚oÅ¼onoÅ›Ä‡ liniowo-logarytmiczna

**Charakterystyka:**
- Czas roÅ›nie **prawie liniowo**, ale wolniej niÅ¼ kwadratowo
- Bardzo dobra zÅ‚oÅ¼onoÅ›Ä‡ dla sortowania
- Praktycznie najlepsza dla porÃ³wnywania sortowaÅ„

**PrzykÅ‚ady:**
- Merge Sort
- Quick Sort (Å›redni przypadek)
- Heap Sort
- WiÄ™kszoÅ›Ä‡ efektywnych algorytmÃ³w sortowania

**Kod (merge sort - koncepcja):**
```java
void mergeSort(int[] array, int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;
        mergeSort(array, left, mid);      // T(n/2)
        mergeSort(array, mid + 1, right); // T(n/2)
        merge(array, left, mid, right);   // O(n)
        // T(n) = 2T(n/2) + O(n) = O(n log n)
    }
}
```

**Wykres:** RoÅ›nie szybciej niÅ¼ liniowo, ale wolniej niÅ¼ kwadratowo

### O(nÂ²) â€” zÅ‚oÅ¼onoÅ›Ä‡ kwadratowa â€” szczegÃ³Å‚owo

**Charakterystyka:**
- Czas roÅ›nie **kwadratowo** z rozmiarem
- Podwajanie danych = 4x czas
- Za wolna dla duÅ¼ych danych

**Intuicja:** To jak sprawdzanie wszystkich par osÃ³b â€” dla n osÃ³b masz n Ã— n = nÂ² par do sprawdzenia.

**PrzykÅ‚ad z Å¼ycia:**
- **Problem:** SprawdÅº, czy w grupie sÄ… dwie osoby z tym samym imieniem
- **Algorytm:** PorÃ³wnaj kaÅ¼dÄ… osobÄ™ z kaÅ¼dÄ…
- **Operacje:** n Ã— n = nÂ² porÃ³wnaÅ„

**PrzykÅ‚ady szczegÃ³Å‚owe:**

**PrzykÅ‚ad 1: Bubble Sort â€” szczegÃ³Å‚owa analiza**
```java
void bubbleSort(int[] array) {
    for (int i = 0; i < array.length; i++) {           // PÄ™tla zewnÄ™trzna
        for (int j = 0; j < array.length - 1 - i; j++) {   // PÄ™tla wewnÄ™trzna
            if (array[j] > array[j + 1]) {
                swap(array, j, j + 1);                  // 3 operacje
            }
        }
    }
}
```

**Analiza krok po kroku:**

**PÄ™tla zewnÄ™trzna:**
- Liczba iteracji: n
- W kaÅ¼dej iteracji wykonuje siÄ™ pÄ™tla wewnÄ™trzna

**PÄ™tla wewnÄ™trzna:**
- Iteracja 1: n-1 porÃ³wnaÅ„
- Iteracja 2: n-2 porÃ³wnaÅ„
- Iteracja 3: n-3 porÃ³wnaÅ„
- ...
- Iteracja n: 0 porÃ³wnaÅ„

**CaÅ‚kowita liczba porÃ³wnaÅ„:**
- (n-1) + (n-2) + (n-3) + ... + 1 + 0
- = n(n-1)/2
- = (nÂ² - n)/2
- UpraszczajÄ…c: O(nÂ²)

**PrzykÅ‚ad 2: Sprawdzanie wszystkich par**
```java
void printAllPairs(int[] array) {
    for (int i = 0; i < array.length; i++) {        // n iteracji
        for (int j = 0; j < array.length; j++) {    // n iteracji
            System.out.println("(" + array[i] + ", " + array[j] + ")");
        }
    }
}
```

**Analiza:**
- Dla kaÅ¼dej wartoÅ›ci i (n moÅ¼liwoÅ›ci)
- Dla kaÅ¼dej wartoÅ›ci j (n moÅ¼liwoÅ›ci)
- Razem: n Ã— n = nÂ² par
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(nÂ²)

**PrzykÅ‚ad 3: MnoÅ¼enie macierzy (naiwna metoda)**
```java
void multiplyMatrices(int[][] A, int[][] B, int[][] C) {
    for (int i = 0; i < n; i++) {           // n iteracji
        for (int j = 0; j < n; j++) {       // n iteracji
            C[i][j] = 0;
            for (int k = 0; k < n; k++) {   // n iteracji
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}
```

**Analiza:**
- Trzy zagnieÅ¼dÅ¼one pÄ™tle po n elementach
- Operacje: n Ã— n Ã— n = nÂ³
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(nÂ³) â€” jeszcze gorsza!

**Tabela porÃ³wnawcza:**
| n | Operacje O(nÂ²) | Czas (przy 1 mld op/s) | PorÃ³wnanie z O(n) |
|---|----------------|------------------------|-------------------|
| 10 | 100 | 0.0000001 s | 10x wiÄ™cej |
| 100 | 10 000 | 0.00001 s | 100x wiÄ™cej |
| 1000 | 1 000 000 | 0.001 s | 1000x wiÄ™cej |
| 10 000 | 100 000 000 | 0.1 s | 10 000x wiÄ™cej |
| 100 000 | 10 000 000 000 | 10 s | 100 000x wiÄ™cej |

**Wykres:** Parabola (roÅ›nie szybko)
```
Czas
  |
  |        â•±
  |       â•±
  |      â•±
  |     â•±
  |    â•±
  |   â•±
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ n
```

**OstrzeÅ¼enie:** 
- Dla n = 1000 â†’ 1 000 000 operacji (~0.001 s) â€” OK
- Dla n = 10 000 â†’ 100 000 000 operacji (~0.1 s) â€” wolne
- Dla n = 100 000 â†’ 10 000 000 000 operacji (~10 s) â€” bardzo wolne!

**Kiedy O(nÂ²) jest akceptowalne?**
- MaÅ‚e dane (n < 1000)
- Proste algorytmy (Å‚atwe do zrozumienia)
- Rzadko wykonywane operacje

**Kiedy unikaÄ‡ O(nÂ²)?**
- DuÅ¼e dane (n > 10 000)
- CzÄ™sto wykonywane operacje
- Aplikacje czasu rzeczywistego

**Wniosek:** O(nÂ²) jest za wolna dla duÅ¼ych danych â€” szukaj lepszych algorytmÃ³w!

### O(nÂ³) â€” zÅ‚oÅ¼onoÅ›Ä‡ szeÅ›cienna

**Charakterystyka:**
- Czas roÅ›nie **szeÅ›ciennie**
- Podwajanie danych = 8x czas
- Bardzo wolna

**PrzykÅ‚ady:**
- Trzy zagnieÅ¼dÅ¼one pÄ™tle
- MnoÅ¼enie macierzy (naiwna metoda)
- Sprawdzanie wszystkich trÃ³jek elementÃ³w

**Kod:**
```java
void multiplyMatrices(int[][] A, int[][] B, int[][] C) {
    for (int i = 0; i < n; i++) {           // n
        for (int j = 0; j < n; j++) {       // n
            for (int k = 0; k < n; k++) {   // n
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
    // O(nÂ³)
}
```

### O(2^n) â€” zÅ‚oÅ¼onoÅ›Ä‡ wykÅ‚adnicza

**Charakterystyka:**
- Czas roÅ›nie **wykÅ‚adniczo**
- KaÅ¼dy nowy element podwaja czas
- Praktycznie nieuÅ¼ywalna dla wiÄ™kszych danych

**PrzykÅ‚ady:**
- Algorytmy brute-force
- Problem komiwojaÅ¼era (TSP) - naiwna metoda
- Generowanie wszystkich podzbiorÃ³w
- Rekurencyjne obliczanie ciÄ…gu Fibonacciego (naiwne)

**Kod (Fibonacci - naiwny):**
```java
int fibonacci(int n) {
    if (n <= 1) return n;
    return fibonacci(n - 1) + fibonacci(n - 2);
    // T(n) = T(n-1) + T(n-2) â‰ˆ O(2^n)
}
```

**Wykres:** RoÅ›nie ekstremalnie szybko

**OstrzeÅ¼enie:** Dla n = 30 â†’ ~1 miliard operacji, dla n = 40 â†’ ~1 bilion operacji

### O(n!) â€” zÅ‚oÅ¼onoÅ›Ä‡ silniowa

**Charakterystyka:**
- Najgorsza moÅ¼liwa zÅ‚oÅ¼onoÅ›Ä‡
- Czas roÅ›nie jak silnia
- Praktycznie nieuÅ¼ywalna nawet dla maÅ‚ych danych

**PrzykÅ‚ady:**
- Generowanie wszystkich permutacji
- Problem komiwojaÅ¼era - sprawdzanie wszystkich Å›cieÅ¼ek
- NiektÃ³re problemy kombinatoryczne

**Kod:**
```java
void generatePermutations(int[] array, int start) {
    if (start == array.length) {
        // przetwÃ³rz permutacjÄ™
        return;
    }
    for (int i = start; i < array.length; i++) {
        swap(array, start, i);
        generatePermutations(array, start + 1);  // O(n!) permutacji
        swap(array, start, i);
    }
}
```

**Wykres:** RoÅ›nie ekstremalnie szybko, jeszcze gorzej niÅ¼ wykÅ‚adnicza

---

## 4) Analiza przypadkÃ³w â€” najlepszy, przeciÄ™tny, najgorszy

### Trzy przypadki analizy:

#### 1. Najlepszy przypadek (Best Case) â€” Î©
- Minimalna liczba operacji
- Najlepsze moÅ¼liwe dane wejÅ›ciowe
- Notacja: Î©(f(n))

**PrzykÅ‚ad - wyszukiwanie liniowe:**
- Najlepszy: Element na pierwszej pozycji â†’ O(1)
- PrzeciÄ™tny: Element w Å›rodku â†’ O(n/2) = O(n)
- Najgorszy: Element na koÅ„cu lub brak â†’ O(n)

#### 2. PrzeciÄ™tny przypadek (Average Case) â€” Î˜
- Oczekiwana liczba operacji
- Losowe dane wejÅ›ciowe
- CzÄ™sto najwaÅ¼niejszy w praktyce

**PrzykÅ‚ad - Quick Sort:**
- Najlepszy: O(n log n)
- PrzeciÄ™tny: O(n log n)
- Najgorszy: O(nÂ²) - gdy pivot jest zawsze skrajnym elementem

#### 3. Najgorszy przypadek (Worst Case) â€” O
- Maksymalna liczba operacji
- Najgorsze moÅ¼liwe dane wejÅ›ciowe
- Notacja: O(f(n))
- NajczÄ™Å›ciej analizowana

**PrzykÅ‚ad - wyszukiwanie binarne:**
- Wszystkie przypadki: O(log n) - zawsze taka sama zÅ‚oÅ¼onoÅ›Ä‡

### PrzykÅ‚ad porÃ³wnawczy - Quick Sort vs Merge Sort:

| Algorytm | Najlepszy | PrzeciÄ™tny | Najgorszy |
|----------|-----------|------------|-----------|
| **Quick Sort** | O(n log n) | O(n log n) | O(nÂ²) |
| **Merge Sort** | O(n log n) | O(n log n) | O(n log n) |

**Wniosek:** Merge Sort ma gwarancjÄ™, Quick Sort jest szybszy w praktyce (lepsze staÅ‚e).

---

## 5) ZÅ‚oÅ¼onoÅ›Ä‡ czasowa vs pamiÄ™ciowa

### ZÅ‚oÅ¼onoÅ›Ä‡ czasowa (Time Complexity)

**Definiuje:** Jak szybko roÅ›nie czas wykonania algorytmu

**Mierzymy w:**
- Liczba operacji podstawowych
- Liczba porÃ³wnaÅ„
- Liczba iteracji pÄ™tli

**PrzykÅ‚ad:**
```java
int sum = 0;
for (int i = 0; i < n; i++) {  // O(n) czasowa
    sum += array[i];
}
```

### ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa (Space Complexity)

**Definiuje:** Jak szybko roÅ›nie zuÅ¼ycie pamiÄ™ci algorytmu

**UwzglÄ™dniamy:**
- PamiÄ™Ä‡ na dane wejÅ›ciowe (czÄ™sto pomijana)
- PamiÄ™Ä‡ pomocnicza (zmienne, stos rekurencyjny)
- PamiÄ™Ä‡ wyjÅ›ciowa (jeÅ›li tworzymy nowÄ… strukturÄ™)

**PrzykÅ‚ad:**
```java
int[] copyArray(int[] original) {
    int[] copy = new int[original.length];  // O(n) pamiÄ™ciowa
    for (int i = 0; i < original.length; i++) {
        copy[i] = original[i];
    }
    return copy;
}
```

### PrzykÅ‚ady rÃ³Å¼nych kombinacji:

| Algorytm | Czasowa | PamiÄ™ciowa |
|----------|---------|------------|
| **Wyszukiwanie liniowe** | O(n) | O(1) - tylko zmienne |
| **Merge Sort** | O(n log n) | O(n) - tablica pomocnicza |
| **Quick Sort** | O(n log n) Å›rednio | O(log n) - stos rekurencyjny |
| **Bubble Sort (in-place)** | O(nÂ²) | O(1) - sortowanie w miejscu |
| **Counting Sort** | O(n + k) | O(k) - tablica licznikÃ³w |

### Trade-off czas vs pamiÄ™Ä‡:

CzÄ™sto moÅ¼emy:
- **ZwiÄ™kszyÄ‡ pamiÄ™Ä‡** â†’ zmniejszyÄ‡ czas (cache, precomputing)
- **ZwiÄ™kszyÄ‡ czas** â†’ zmniejszyÄ‡ pamiÄ™Ä‡ (kompresja, obliczenia na Å¼Ä…danie)

---

## 6) Analiza zÅ‚oÅ¼onoÅ›ci â€” metody

### Metoda 1: Zliczanie operacji podstawowych

**Kroki:**
1. Zidentyfikuj operacje podstawowe
2. Zlicz ile razy siÄ™ wykonujÄ…
3. WyraÅº jako funkcjÄ™ n (rozmiar danych)
4. UproÅ›Ä‡ uÅ¼ywajÄ…c notacji O

**PrzykÅ‚ad szczegÃ³Å‚owy â€” krok po kroku:**
```java
int sum = 0;                    // Krok 1
for (int i = 0; i < n; i++) {   // Krok 2
    sum += array[i];            // Krok 3
}
return sum;                     // Krok 4
```

**Analiza krok po kroku:**

**Krok 1: Inicjalizacja**
- Operacje: 1 (przypisanie sum = 0)
- ZÅ‚oÅ¼onoÅ›Ä‡: O(1)

**Krok 2: PÄ™tla for**
- Liczba iteracji: n
- Operacje w kaÅ¼dej iteracji pÄ™tli:
  - Sprawdzenie warunku (i < n): 1
  - Inkrementacja i (i++): 1
- Razem na pÄ™tlÄ™: n Ã— 2 = 2n

**Krok 3: TreÅ›Ä‡ pÄ™tli**
- Operacje w kaÅ¼dej iteracji:
  - DostÄ™p do tablicy (array[i]): 1
  - Dodawanie (sum + array[i]): 1
  - Przypisanie (sum = ...): 1
- Razem: 3 operacje na iteracjÄ™
- Dla n iteracji: 3n

**Krok 4: Return**
- Operacje: 1

**Podsumowanie:**
- Razem: 1 + 2n + 3n + 1 = 5n + 2
- UpraszczajÄ…c: O(n) (ignorujemy staÅ‚e i niÅ¼sze potÄ™gi)

**Weryfikacja dla rÃ³Å¼nych n:**
- n = 10: 5 Ã— 10 + 2 = 52 operacje
- n = 100: 5 Ã— 100 + 2 = 502 operacje
- n = 1000: 5 Ã— 1000 + 2 = 5002 operacje
- **Wzrost liniowy** â†’ O(n) âœ“

### Metoda 2: Analiza pÄ™tli

**Zasady:**
- PÄ™tla po n elementach: O(n)
- ZagnieÅ¼dÅ¼one pÄ™tle: O(n * m) = O(nÂ²) jeÅ›li n = m
- PÄ™tla z podziaÅ‚em: O(log n)

**PrzykÅ‚ady szczegÃ³Å‚owe:**

**PrzykÅ‚ad 1: Pojedyncza pÄ™tla â€” O(n)**
```java
for (int i = 0; i < n; i++) {
    System.out.println(i);  // 1 operacja w kaÅ¼dej iteracji
}
```
**Analiza:**
- Liczba iteracji: n
- Operacje na iteracjÄ™: 1
- Razem: n Ã— 1 = n
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(n)

**PrzykÅ‚ad 2: ZagnieÅ¼dÅ¼one pÄ™tle â€” O(nÂ²)**
```java
for (int i = 0; i < n; i++) {        // n iteracji
    for (int j = 0; j < n; j++) {    // n iteracji
        System.out.println(i + ", " + j);  // 1 operacja
    }
}
```
**Analiza:**
- PÄ™tla zewnÄ™trzna: n iteracji
- PÄ™tla wewnÄ™trzna: n iteracji (dla kaÅ¼dej iteracji zewnÄ™trznej)
- Operacje: n Ã— n Ã— 1 = nÂ²
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(nÂ²)

**PrzykÅ‚ad 3: PÄ™tla z podziaÅ‚em â€” O(log n)**
```java
for (int i = n; i > 0; i /= 2) {
    System.out.println(i);  // 1 operacja w kaÅ¼dej iteracji
}
```
**Analiza:**
- Iteracja 1: i = n
- Iteracja 2: i = n/2
- Iteracja 3: i = n/4
- Iteracja 4: i = n/8
- ...
- Iteracja k: i = n/(2^(k-1)) = 1
- n/(2^(k-1)) = 1 â†’ n = 2^(k-1) â†’ k-1 = logâ‚‚(n) â†’ k = logâ‚‚(n) + 1
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(log n)

**PrzykÅ‚ad 4: ZagnieÅ¼dÅ¼one pÄ™tle z rÃ³Å¼nymi zakresami â€” O(n Ã— m)**
```java
for (int i = 0; i < n; i++) {        // n iteracji
    for (int j = 0; j < m; j++) {    // m iteracji
        System.out.println(i + ", " + j);
    }
}
```
**Analiza:**
- PÄ™tla zewnÄ™trzna: n iteracji
- PÄ™tla wewnÄ™trzna: m iteracji
- Operacje: n Ã— m
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(n Ã— m)
- JeÅ›li n = m: O(nÂ²)

### Metoda 3: Analiza rekurencji

**Twierdzenie Master (Master Theorem):**

JeÅ›li T(n) = a * T(n/b) + f(n), gdzie a â‰¥ 1, b > 1, to:

1. JeÅ›li f(n) = O(n^(log_b(a) - Îµ)) dla Îµ > 0:
   T(n) = Î˜(n^(log_b(a)))

2. JeÅ›li f(n) = Î˜(n^(log_b(a))):
   T(n) = Î˜(n^(log_b(a)) * log n)

3. JeÅ›li f(n) = Î©(n^(log_b(a) + Îµ)) dla Îµ > 0:
   T(n) = Î˜(f(n))

**PrzykÅ‚ad 1: Merge Sort â€” szczegÃ³Å‚owa analiza**

**RÃ³wnanie rekurencyjne:**
T(n) = 2T(n/2) + O(n)

**Krok 1: Identyfikacja parametrÃ³w**
- a = 2 (liczba podproblemÃ³w)
- b = 2 (rozmiar kaÅ¼dego podproblemu = n/b)
- f(n) = O(n) (praca na kaÅ¼dym poziomie)

**Krok 2: Obliczenie log_b(a)**
- log_b(a) = logâ‚‚(2) = 1

**Krok 3: PorÃ³wnanie f(n) z n^(log_b(a))**
- n^(log_b(a)) = n^1 = n
- f(n) = O(n) = Î˜(n)
- **Wniosek:** f(n) = Î˜(n^(log_b(a))) â†’ **przypadek 2**

**Krok 4: Zastosowanie wzoru**
- Przypadek 2: T(n) = Î˜(n^(log_b(a)) * log n)
- T(n) = Î˜(n^1 * log n) = Î˜(n log n)

**Weryfikacja:**
- Merge Sort rzeczywiÅ›cie ma zÅ‚oÅ¼onoÅ›Ä‡ O(n log n) âœ“

**PrzykÅ‚ad 2: Binary Search â€” szczegÃ³Å‚owa analiza**

**RÃ³wnanie rekurencyjne:**
T(n) = T(n/2) + O(1)

**Krok 1: Identyfikacja parametrÃ³w**
- a = 1 (jeden podproblem)
- b = 2 (rozmiar podproblemu = n/2)
- f(n) = O(1) (staÅ‚a praca)

**Krok 2: Obliczenie log_b(a)**
- log_b(a) = logâ‚‚(1) = 0

**Krok 3: PorÃ³wnanie f(n) z n^(log_b(a))**
- n^(log_b(a)) = n^0 = 1
- f(n) = O(1) = O(n^0)
- **Wniosek:** f(n) = O(n^(log_b(a) - Îµ)) dla Îµ > 0 â†’ **przypadek 1**

**Krok 4: Zastosowanie wzoru**
- Przypadek 1: T(n) = Î˜(n^(log_b(a)))
- T(n) = Î˜(n^0) = Î˜(1)
- **ALE:** To nie jest poprawne! Musimy przeanalizowaÄ‡ dokÅ‚adniej.

**Poprawna analiza:**
- Binary Search dzieli problem na poÅ‚owÄ™: T(n) = T(n/2) + 1
- T(n) = T(n/2) + 1
- T(n/2) = T(n/4) + 1
- ...
- T(1) = 1
- T(n) = logâ‚‚(n) + 1 = O(log n)

**PrzykÅ‚ad 3: Quick Sort (Å›redni przypadek)**

**RÃ³wnanie rekurencyjne:**
T(n) = 2T(n/2) + O(n)

**Analiza:**
- a = 2, b = 2, f(n) = O(n)
- log_b(a) = 1
- f(n) = Î˜(n) = Î˜(n^1) â†’ przypadek 2
- T(n) = Î˜(n log n)

**PrzykÅ‚ad 4: Algorytm dziel-i-zwyciÄ™Å¼aj z 3 podproblemami**

**RÃ³wnanie:**
T(n) = 3T(n/2) + O(n)

**Analiza:**
- a = 3, b = 2, f(n) = O(n)
- log_b(a) = logâ‚‚(3) â‰ˆ 1.585
- n^(log_b(a)) = n^1.585
- f(n) = O(n) = O(n^1) < O(n^1.585) â†’ przypadek 1
- T(n) = Î˜(n^(logâ‚‚(3))) â‰ˆ Î˜(n^1.585)

### Metoda 4: Drzewo rekurencji

**Kroki:**
1. Narysuj drzewo wywoÅ‚aÅ„ rekurencyjnych
2. Policz caÅ‚kowitÄ… pracÄ™ na kaÅ¼dym poziomie
3. Zsumuj wszystkie poziomy

**PrzykÅ‚ad - Merge Sort â€” szczegÃ³Å‚owa analiza drzewa:**

**RÃ³wnanie:** T(n) = 2T(n/2) + O(n)

**Drzewo rekurencji dla n = 8:**

```
                    Poziom 0: O(8) = O(n)
                         |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |                                   |
    Poziom 1: O(4)                    Poziom 1: O(4)
    = O(n/2)                          = O(n/2)
        |                                   |
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”                         â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    |       |                         |       |
Poziom 2: Poziom 2:              Poziom 2: Poziom 2:
O(2)     O(2)                   O(2)     O(2)
= O(n/4) = O(n/4)                = O(n/4) = O(n/4)
    |       |                         |       |
  ...     ...                       ...     ...
```

**Analiza poziomÃ³w:**

**Poziom 0:**
- Liczba wÄ™zÅ‚Ã³w: 1
- Praca na wÄ™zeÅ‚: O(n)
- Praca caÅ‚kowita: O(n)

**Poziom 1:**
- Liczba wÄ™zÅ‚Ã³w: 2
- Praca na wÄ™zeÅ‚: O(n/2)
- Praca caÅ‚kowita: 2 Ã— O(n/2) = O(n)

**Poziom 2:**
- Liczba wÄ™zÅ‚Ã³w: 4
- Praca na wÄ™zeÅ‚: O(n/4)
- Praca caÅ‚kowita: 4 Ã— O(n/4) = O(n)

**Poziom k:**
- Liczba wÄ™zÅ‚Ã³w: 2^k
- Praca na wÄ™zeÅ‚: O(n/(2^k))
- Praca caÅ‚kowita: 2^k Ã— O(n/(2^k)) = O(n)

**Liczba poziomÃ³w:**
- Poziom 0: n elementÃ³w
- Poziom 1: n/2 elementÃ³w
- Poziom 2: n/4 elementÃ³w
- ...
- Poziom logâ‚‚(n): n/(2^(logâ‚‚(n))) = n/n = 1 element
- **Liczba poziomÃ³w:** logâ‚‚(n) + 1

**CaÅ‚kowita praca:**
- (logâ‚‚(n) + 1) poziomÃ³w Ã— O(n) na poziom
- = O(n log n)

**Weryfikacja dla n = 8:**
- PoziomÃ³w: logâ‚‚(8) + 1 = 3 + 1 = 4
- Praca: 4 Ã— O(8) = O(32) = O(n log n) âœ“

---

## 7) PrzykÅ‚ady analizy konkretnych algorytmÃ³w

### PrzykÅ‚ad 1: Wyszukiwanie liniowe

```java
int linearSearch(int[] array, int target) {
    for (int i = 0; i < array.length; i++) {      // n iteracji
        if (array[i] == target) return i;         // O(1) operacja
    }
    return -1;
}
```

**Analiza:**
- **Najlepszy przypadek:** O(1) - element na pierwszej pozycji
- **PrzeciÄ™tny przypadek:** O(n/2) = O(n) - element w Å›rodku
- **Najgorszy przypadek:** O(n) - element na koÅ„cu lub brak
- **PamiÄ™ciowa:** O(1) - tylko zmienne

**ZÅ‚oÅ¼onoÅ›Ä‡:** O(n) czasowa, O(1) pamiÄ™ciowa

### PrzykÅ‚ad 2: Wyszukiwanie binarne

```java
int binarySearch(int[] array, int target) {
    int left = 0, right = array.length - 1;
    while (left <= right) {
        int mid = (left + right) / 2;
        if (array[mid] == target) return mid;
        if (array[mid] < target) left = mid + 1;
        else right = mid - 1;
    }
    return -1;
}
```

**Analiza:**
- W kaÅ¼dym kroku obszar przeszukiwania zmniejsza siÄ™ o poÅ‚owÄ™
- n â†’ n/2 â†’ n/4 â†’ ... â†’ 1
- Liczba krokÃ³w: logâ‚‚(n)
- **Wszystkie przypadki:** O(log n)

**ZÅ‚oÅ¼onoÅ›Ä‡:** O(log n) czasowa, O(1) pamiÄ™ciowa

### PrzykÅ‚ad 3: Bubble Sort

```java
void bubbleSort(int[] array) {
    for (int i = 0; i < array.length; i++) {              // n iteracji
        for (int j = 0; j < array.length - 1 - i; j++) {  // n-i iteracji
            if (array[j] > array[j + 1]) {
                swap(array, j, j + 1);
            }
        }
    }
}
```

**Analiza:**
- ZewnÄ™trzna pÄ™tla: n iteracji
- WewnÄ™trzna pÄ™tla: (n-1) + (n-2) + ... + 1 = n(n-1)/2
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(nÂ²)

**ZÅ‚oÅ¼onoÅ›Ä‡:** O(nÂ²) czasowa, O(1) pamiÄ™ciowa (in-place)

### PrzykÅ‚ad 4: Merge Sort

```java
void mergeSort(int[] array, int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;
        mergeSort(array, left, mid);           // T(n/2)
        mergeSort(array, mid + 1, right);      // T(n/2)
        merge(array, left, mid, right);        // O(n)
    }
}
```

**Analiza:**
- T(n) = 2T(n/2) + O(n)
- Z Master Theorem: T(n) = O(n log n)
- PamiÄ™Ä‡: O(n) na tablicÄ™ pomocniczÄ… + O(log n) na stos rekurencyjny = O(n)

**ZÅ‚oÅ¼onoÅ›Ä‡:** O(n log n) czasowa, O(n) pamiÄ™ciowa

### PrzykÅ‚ad 5: Fibonacci (naiwny)

```java
int fibonacci(int n) {
    if (n <= 1) return n;
    return fibonacci(n - 1) + fibonacci(n - 2);
}
```

**Analiza:**
- T(n) = T(n-1) + T(n-2) + O(1)
- Drzewo rekurencji ma wysokoÅ›Ä‡ n i wykÅ‚adniczÄ… liczbÄ™ wÄ™zÅ‚Ã³w
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(2^n) - bardzo wolna!

**ZÅ‚oÅ¼onoÅ›Ä‡:** O(2^n) czasowa, O(n) pamiÄ™ciowa (gÅ‚Ä™bokoÅ›Ä‡ rekurencji)

**Lepsze rozwiÄ…zanie (dynamiczne programowanie):**
```java
int fibonacciDP(int n) {
    int[] dp = new int[n + 1];
    dp[0] = 0; dp[1] = 1;
    for (int i = 2; i <= n; i++) {
        dp[i] = dp[i-1] + dp[i-2];  // O(n) iteracji
    }
    return dp[n];
}
```
**ZÅ‚oÅ¼onoÅ›Ä‡:** O(n) czasowa, O(n) pamiÄ™ciowa

---

## 8) ZÅ‚oÅ¼onoÅ›Ä‡ amortyzowana

### Definicja

**ZÅ‚oÅ¼onoÅ›Ä‡ amortyzowana** to Å›rednia zÅ‚oÅ¼onoÅ›Ä‡ operacji w sekwencji operacji, nawet jeÅ›li pojedyncze operacje mogÄ… byÄ‡ kosztowne.

### PrzykÅ‚ad: Dynamiczna tablica (ArrayList)

**Operacje:**
- **Dodanie elementu:** O(1) amortyzowana (choÄ‡ czasami O(n) gdy trzeba powiÄ™kszyÄ‡)
- **Pojedyncza operacja:** moÅ¼e byÄ‡ O(n) (przy powiÄ™kszaniu)
- **Sekwencja n operacji:** O(n) caÅ‚kowicie

**Analiza:**
- ZaÅ‚Ã³Å¼my, Å¼e zaczynamy od tablicy rozmiaru 1
- PowiÄ™kszamy gdy brakuje miejsca (podwajamy rozmiar)
- Koszt: 1 + 2 + 4 + 8 + ... + n/2 + n = O(n)
- n operacji daje O(n) caÅ‚kowity koszt
- **Amortyzowana zÅ‚oÅ¼onoÅ›Ä‡:** O(n) / n = O(1)

### Metoda kontowa (Accounting Method)

Przypisujemy "kredyt" tanim operacjom, ktÃ³ry "pÅ‚acimy" za drogie operacje.

### Metoda potencjaÅ‚u (Potential Method)

Definiujemy funkcjÄ™ potencjaÅ‚u, ktÃ³ra mierzy "stan" struktury danych.

---

## 9) Praktyczne wskazÃ³wki i triki

### Jak upraszczaÄ‡ wyraÅ¼enia:

1. **Ignoruj staÅ‚e:**
   - 3n + 5 = O(n)
   - 1000n = O(n)

2. **Ignoruj niÅ¼sze potÄ™gi:**
   - nÂ² + n = O(nÂ²)
   - nÂ³ + nÂ² + n = O(nÂ³)

3. **Ignoruj logarytmiczne czynniki przy wiÄ™kszych potÄ™gach:**
   - nÂ² + n log n = O(nÂ²)
   - nÂ³ + nÂ² log n = O(nÂ³)

4. **Wybierz najgorszÄ… gaÅ‚Ä…Åº:**
   - if (condition) O(n) else O(log n) = O(n)

### CzÄ™ste bÅ‚Ä™dy:

1. **Mylenie O(n) z Î˜(n):**
   - O(n) mÃ³wi "nie gorsze niÅ¼ n"
   - Î˜(n) mÃ³wi "dokÅ‚adnie n"

2. **Ignorowanie najlepszego przypadku:**
   - Quick Sort ma O(nÂ²) w najgorszym, ale O(n log n) Å›rednio

3. **NieuwzglÄ™dnianie pamiÄ™ci:**
   - Merge Sort: O(n log n) czas, ale O(n) pamiÄ™Ä‡
   - Quick Sort: O(n log n) czas, O(log n) pamiÄ™Ä‡

4. **Mylenie zÅ‚oÅ¼onoÅ›ci z czasem wykonania:**
   - ZÅ‚oÅ¼onoÅ›Ä‡ mÃ³wi o wzroÅ›cie, nie o absolutnym czasie
   - O(n) algorytm moÅ¼e byÄ‡ wolniejszy od O(nÂ²) dla maÅ‚ych n (staÅ‚e czynniki!)

### Kiedy zÅ‚oÅ¼onoÅ›Ä‡ ma znaczenie:

**DuÅ¼e dane (n > 10 000):**
- RÃ³Å¼nica miÄ™dzy O(n) a O(nÂ²) jest ogromna
- WaÅ¼na jest dobra zÅ‚oÅ¼onoÅ›Ä‡

**MaÅ‚e dane (n < 100):**
- StaÅ‚e czynniki mogÄ… byÄ‡ waÅ¼niejsze
- Prosty algorytm O(nÂ²) moÅ¼e byÄ‡ szybszy niÅ¼ skomplikowany O(n log n)

**PrzykÅ‚ad:**
- Bubble Sort (O(nÂ²)) moÅ¼e byÄ‡ szybszy od Quick Sort (O(n log n)) dla n < 50
- Bo Bubble Sort ma maÅ‚e staÅ‚e, a Quick Sort ma overhead

---

## 10) PorÃ³wnanie algorytmÃ³w sortowania

| Algorytm | Najlepszy | PrzeciÄ™tny | Najgorszy | PamiÄ™ciowa | Stabilny |
|----------|-----------|------------|-----------|------------|----------|
| **Bubble Sort** | O(n) | O(nÂ²) | O(nÂ²) | O(1) | Tak |
| **Selection Sort** | O(nÂ²) | O(nÂ²) | O(nÂ²) | O(1) | Nie |
| **Insertion Sort** | O(n) | O(nÂ²) | O(nÂ²) | O(1) | Tak |
| **Merge Sort** | O(n log n) | O(n log n) | O(n log n) | O(n) | Tak |
| **Quick Sort** | O(n log n) | O(n log n) | O(nÂ²) | O(log n) | Nie |
| **Heap Sort** | O(n log n) | O(n log n) | O(n log n) | O(1) | Nie |
| **Counting Sort** | O(n + k) | O(n + k) | O(n + k) | O(k) | Tak |

**Uwagi:**
- **k** = zakres wartoÅ›ci (dla liczb od 0 do k-1)
- **Stabilny** = zachowuje kolejnoÅ›Ä‡ rÃ³wnych elementÃ³w
- **In-place** = O(1) pamiÄ™ciowa (oprÃ³cz danych wejÅ›ciowych)

---

## 11) ZÅ‚oÅ¼onoÅ›Ä‡ dla struktur danych

### Operacje podstawowe:

| Struktura | Wstawienie | Wyszukiwanie | UsuniÄ™cie | Min/Max |
|-----------|------------|--------------|-----------|---------|
| **Tabela (Array)** | O(1) | O(n) | O(n) | O(n) |
| **Lista (LinkedList)** | O(1) | O(n) | O(n) | O(n) |
| **Hash Table** | O(1)* | O(1)* | O(1)* | O(n) |
| **BST (niezbalansowany)** | O(n) | O(n) | O(n) | O(n) |
| **BST (zbalansowany)** | O(log n) | O(log n) | O(log n) | O(log n) |
| **Heap** | O(log n) | O(n) | O(log n) | O(1) |

*O(1) amortyzowana, O(n) w najgorszym przypadku (kolizje)

### WybÃ³r struktury danych:

**Hash Table:** Gdy potrzebujesz szybkiego wyszukiwania/wstawiania
**BST:** Gdy potrzebujesz uporzÄ…dkowanych danych i operacji zakresowych
**Heap:** Gdy potrzebujesz szybkiego dostÄ™pu do min/max
**Array:** Gdy masz indeksy i potrzebujesz szybkiego dostÄ™pu

---

## 12) Kluczowe zdania na obronÄ™

1. **Big O (O)** â€” gÃ³rna granica, najgorszy przypadek, "algorytm nie gorszy niÅ¼"

2. **Big Omega (Î©)** â€” dolna granica, najlepszy przypadek, "algorytm nie lepszy niÅ¼"

3. **Big Theta (Î˜)** â€” dokÅ‚adna zÅ‚oÅ¼onoÅ›Ä‡, gdy O = Î©

4. **Hierarchia zÅ‚oÅ¼onoÅ›ci:** O(1) < O(log n) < O(n) < O(n log n) < O(nÂ²) < O(2^n) < O(n!)

5. **O(1)** â€” staÅ‚a, niezaleÅ¼na od rozmiaru (dostÄ™p do tablicy)

6. **O(log n)** â€” logarytmiczna, bardzo dobra (binary search, BST)

7. **O(n)** â€” liniowa, proporcjonalna (przejÅ›cie przez tablicÄ™)

8. **O(n log n)** â€” liniowo-logarytmiczna, dobra dla sortowania (Merge Sort, Quick Sort)

9. **O(nÂ²)** â€” kwadratowa, wolna (dwie zagnieÅ¼dÅ¼one pÄ™tle, Bubble Sort)

10. **O(2^n)** â€” wykÅ‚adnicza, praktycznie nieuÅ¼ywalna (naiwny Fibonacci, brute-force)

11. **Analiza przypadkÃ³w:** najlepszy (Î©), przeciÄ™tny (Î˜), najgorszy (O)

12. **ZÅ‚oÅ¼onoÅ›Ä‡ czasowa** vs **pamiÄ™ciowa** â€” mogÄ… siÄ™ rÃ³Å¼niÄ‡

13. **ZÅ‚oÅ¼onoÅ›Ä‡ amortyzowana** â€” Å›rednia zÅ‚oÅ¼onoÅ›Ä‡ operacji w sekwencji

14. **Master Theorem** â€” metoda analizy rekurencyjnych algorytmÃ³w dziel-i-zwyciÄ™Å¼aj

15. **W praktyce:** dla maÅ‚ych danych staÅ‚e czynniki mogÄ… byÄ‡ waÅ¼niejsze niÅ¼ zÅ‚oÅ¼onoÅ›Ä‡

16. **Trade-off:** czas vs pamiÄ™Ä‡ â€” czÄ™sto moÅ¼emy wymieniÄ‡ jedno na drugie

17. **Merge Sort** â€” O(n log n) zawsze, stabilny, ale O(n) pamiÄ™ci

18. **Quick Sort** â€” O(n log n) Å›rednio, O(nÂ²) najgorszy, ale szybszy w praktyce

19. **Binary Search** â€” O(log n) â€” bardzo efektywne wyszukiwanie w posortowanej tablicy

20. **Hash Table** â€” O(1) amortyzowana dla wstawiania/wyszukiwania (O(n) w najgorszym przypadku)

---

## 13) MateriaÅ‚y do nauki â€” linki i zasoby

### Strony internetowe z interaktywnymi wizualizacjami:

**1. VisuAlgo â€” Algorytmy wizualizowane**
- **Link:** https://visualgo.net/
- **Opis:** Interaktywne wizualizacje algorytmÃ³w sortowania, wyszukiwania, grafÃ³w
- **Zalety:** MoÅ¼esz zobaczyÄ‡, jak algorytmy dziaÅ‚ajÄ… krok po kroku
- **Przydatne dla:** Zrozumienia, jak dziaÅ‚ajÄ… algorytmy

**2. Big-O Cheat Sheet**
- **Link:** https://www.bigocheatsheet.com/
- **Opis:** Kompletna Å›ciÄ…ga zÅ‚oÅ¼onoÅ›ci algorytmÃ³w i struktur danych
- **Zalety:** Szybkie odniesienie do zÅ‚oÅ¼onoÅ›ci
- **Przydatne dla:** Szybkiego sprawdzenia zÅ‚oÅ¼onoÅ›ci

**3. Algorithm Visualizer**
- **Link:** https://algorithm-visualizer.org/
- **Opis:** Wizualizacje rÃ³Å¼nych algorytmÃ³w z kodem
- **Zalety:** MoÅ¼esz zobaczyÄ‡ kod i wizualizacjÄ™ jednoczeÅ›nie

### Kursy online:

**4. Khan Academy â€” Algorithms**
- **Link:** https://www.khanacademy.org/computing/computer-science/algorithms
- **Opis:** Darmowy kurs podstaw algorytmÃ³w
- **Zalety:** Od podstaw, z przykÅ‚adami i Ä‡wiczeniami

**5. Coursera â€” Algorithms Specialization (Stanford)**
- **Link:** https://www.coursera.org/specializations/algorithms
- **Opis:** Kompleksowy kurs algorytmÃ³w
- **Zalety:** Profesjonalny, z certyfikatami
- **Uwaga:** PÅ‚atny, ale czÄ™sto sÄ… darmowe audyty

**6. MIT OpenCourseWare â€” Introduction to Algorithms**
- **Link:** https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/
- **Opis:** MateriaÅ‚y z MIT
- **Zalety:** Darmowe, wysokiej jakoÅ›ci

### KsiÄ…Å¼ki (PDF dostÄ™pne online):

**7. "Introduction to Algorithms" (CLRS)**
- **Autorzy:** Cormen, Leiserson, Rivest, Stein
- **Opis:** Klasyczna ksiÄ…Å¼ka o algorytmach
- **Zalety:** Kompleksowa, szczegÃ³Å‚owa
- **Link do PDF:** Szukaj "CLRS algorithms pdf" w Google

**8. "Algorithms" (Sedgewick)**
- **Autor:** Robert Sedgewick
- **Opis:** Praktyczne podejÅ›cie do algorytmÃ³w
- **Zalety:** Åatwiejsza niÅ¼ CLRS, z przykÅ‚adami w Javie

### Platformy do Ä‡wiczeÅ„:

**9. LeetCode**
- **Link:** https://leetcode.com/
- **Opis:** Zadania programistyczne z analizÄ… zÅ‚oÅ¼onoÅ›ci
- **Zalety:** Praktyka, rankingi, wyjaÅ›nienia rozwiÄ…zaÅ„
- **Przydatne dla:** Ä†wiczenia analizy zÅ‚oÅ¼onoÅ›ci

**10. HackerRank**
- **Link:** https://www.hackerrank.com/
- **Opis:** Zadania algorytmiczne z testami
- **Zalety:** RÃ³Å¼ne poziomy trudnoÅ›ci

**11. Codeforces**
- **Link:** https://codeforces.com/
- **Opis:** Zawody programistyczne
- **Zalety:** Zaawansowane zadania, analiza zÅ‚oÅ¼onoÅ›ci jest kluczowa

### Filmy na YouTube:

**12. Abdul Bari â€” Algorithms**
- **Link:** https://www.youtube.com/c/AbdulBari
- **Opis:** SzczegÃ³Å‚owe wyjaÅ›nienia algorytmÃ³w
- **Zalety:** Bardzo szczegÃ³Å‚owe, krok po kroku

**13. Back To Back SWE**
- **Link:** https://www.youtube.com/c/BackToBackSWE
- **Opis:** WyjaÅ›nienia algorytmÃ³w z przykÅ‚adami
- **Zalety:** Praktyczne podejÅ›cie

### NarzÄ™dzia do wizualizacji:

**14. Python Tutor**
- **Link:** https://pythontutor.com/
- **Opis:** Wizualizacja wykonania kodu krok po kroku
- **Zalety:** MoÅ¼esz zobaczyÄ‡, jak kod dziaÅ‚a linia po linii

**15. Big-O Calculator**
- **Link:** Szukaj "big o calculator online"
- **Opis:** Kalkulatory do analizy zÅ‚oÅ¼onoÅ›ci
- **Zalety:** Szybkie sprawdzenie zÅ‚oÅ¼onoÅ›ci

### Praktyczne wskazÃ³wki do nauki:

**1. Zacznij od podstaw:**
- Zrozum, co to jest zÅ‚oÅ¼onoÅ›Ä‡
- Naucz siÄ™ notacji Big O
- Przeanalizuj proste algorytmy

**2. Ä†wicz analizÄ™:**
- WeÅº prosty algorytm
- Zlicz operacje krok po kroku
- WyraÅº jako funkcjÄ™ n
- UproÅ›Ä‡ do notacji O

**3. PorÃ³wnuj algorytmy:**
- WeÅº ten sam problem
- PorÃ³wnaj rÃ³Å¼ne algorytmy
- Zobacz rÃ³Å¼nicÄ™ w zÅ‚oÅ¼onoÅ›ci

**4. Wizualizuj:**
- UÅ¼yj VisuAlgo lub podobnych narzÄ™dzi
- Zobacz, jak algorytmy dziaÅ‚ajÄ…
- Zrozum, dlaczego majÄ… takÄ… zÅ‚oÅ¼onoÅ›Ä‡

**5. Ä†wicz na zadaniach:**
- RozwiÄ…zuj zadania na LeetCode
- Analizuj zÅ‚oÅ¼onoÅ›Ä‡ swoich rozwiÄ…zaÅ„
- PorÃ³wnuj z optymalnymi rozwiÄ…zaniami

### PrzykÅ‚adowy plan nauki:

**TydzieÅ„ 1: Podstawy**
- Notacja Big O, Omega, Theta
- O(1), O(log n), O(n)
- Proste przykÅ‚ady analizy

**TydzieÅ„ 2: Klasy zÅ‚oÅ¼onoÅ›ci**
- O(n log n), O(nÂ²), O(nÂ³)
- O(2^n), O(n!)
- PorÃ³wnania i wykresy

**TydzieÅ„ 3: Analiza algorytmÃ³w**
- Metody analizy (zliczanie, pÄ™tle, rekurencja)
- Master Theorem
- PrzykÅ‚ady konkretnych algorytmÃ³w

**TydzieÅ„ 4: Praktyka**
- RozwiÄ…zywanie zadaÅ„
- Analiza zÅ‚oÅ¼onoÅ›ci struktur danych
- PorÃ³wnywanie algorytmÃ³w

---

## 14) Dodatkowe przykÅ‚ady analizy â€” krok po kroku

### PrzykÅ‚ad 1: Analiza prostego algorytmu sumowania

**Kod:**
```java
int sum(int[] array) {
    int sum = 0;                    // Krok 1
    for (int i = 0; i < array.length; i++) {  // Krok 2
        sum += array[i];            // Krok 3
    }
    return sum;                     // Krok 4
}
```

**Analiza krok po kroku:**

**Krok 1: Inicjalizacja**
- Operacje: 1 (przypisanie)
- ZÅ‚oÅ¼onoÅ›Ä‡: O(1)

**Krok 2: PÄ™tla for**
- Liczba iteracji: n (dÅ‚ugoÅ›Ä‡ tablicy)
- Operacje w kaÅ¼dej iteracji:
  - Sprawdzenie warunku: 1
  - Inkrementacja i: 1
- Razem na pÄ™tlÄ™: n Ã— 2 = 2n

**Krok 3: TreÅ›Ä‡ pÄ™tli**
- Operacje w kaÅ¼dej iteracji:
  - DostÄ™p do tablicy: array[i] = 1
  - Dodawanie: sum + array[i] = 1
  - Przypisanie: sum = ... = 1
- Razem: 3 operacje na iteracjÄ™
- Dla n iteracji: 3n

**Krok 4: Return**
- Operacje: 1

**Podsumowanie:**
- Razem: 1 + 2n + 3n + 1 = 5n + 2
- UpraszczajÄ…c: O(n)

**Weryfikacja:**
- Dla n = 10: 5 Ã— 10 + 2 = 52 operacje
- Dla n = 100: 5 Ã— 100 + 2 = 502 operacje
- Dla n = 1000: 5 Ã— 1000 + 2 = 5002 operacje
- **Wzrost liniowy** â†’ O(n) âœ“

### PrzykÅ‚ad 2: Analiza zagnieÅ¼dÅ¼onych pÄ™tli

**Kod:**
```java
void printPairs(int[] array) {
    for (int i = 0; i < array.length; i++) {        // PÄ™tla zewnÄ™trzna
        for (int j = 0; j < array.length; j++) {    // PÄ™tla wewnÄ™trzna
            System.out.println(array[i] + ", " + array[j]);
        }
    }
}
```

**Analiza krok po kroku:**

**PÄ™tla zewnÄ™trzna:**
- Liczba iteracji: n
- W kaÅ¼dej iteracji wykonuje siÄ™ pÄ™tla wewnÄ™trzna

**PÄ™tla wewnÄ™trzna:**
- Liczba iteracji: n
- Operacje w kaÅ¼dej iteracji:
  - DostÄ™p: array[i] = 1
  - DostÄ™p: array[j] = 1
  - Konkatenacja: 2
  - Print: 1
  - Razem: ~5 operacji

**Obliczenia:**
- Dla kaÅ¼dej iteracji zewnÄ™trznej: n iteracji wewnÄ™trznych
- Operacje na parÄ™ pÄ™tli: n Ã— n Ã— 5 = 5nÂ²
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(nÂ²)

**Weryfikacja:**
- Dla n = 10: 5 Ã— 100 = 500 operacji
- Dla n = 100: 5 Ã— 10 000 = 50 000 operacji
- Dla n = 1000: 5 Ã— 1 000 000 = 5 000 000 operacji
- **Wzrost kwadratowy** â†’ O(nÂ²) âœ“

### PrzykÅ‚ad 3: Analiza rekurencyjnego algorytmu

**Kod (obliczanie silni):**
```java
int factorial(int n) {
    if (n <= 1) {           // Warunek bazowy
        return 1;
    }
    return n * factorial(n - 1);  // Rekurencja
}
```

**Analiza krok po kroku:**

**RÃ³wnanie rekurencyjne:**
- T(n) = T(n-1) + O(1)
- T(1) = O(1) (warunek bazowy)

**RozwiÄ…zanie:**
- T(n) = T(n-1) + 1
- T(n-1) = T(n-2) + 1
- T(n-2) = T(n-3) + 1
- ...
- T(2) = T(1) + 1
- T(1) = 1

**PodstawiajÄ…c wstecz:**
- T(n) = T(n-1) + 1
- = [T(n-2) + 1] + 1 = T(n-2) + 2
- = [T(n-3) + 1] + 2 = T(n-3) + 3
- = ...
- = T(1) + (n-1) = 1 + (n-1) = n

**ZÅ‚oÅ¼onoÅ›Ä‡:** O(n)

**Weryfikacja:**
- factorial(5) wywoÅ‚uje: factorial(5) â†’ factorial(4) â†’ factorial(3) â†’ factorial(2) â†’ factorial(1)
- Liczba wywoÅ‚aÅ„: 5 = n âœ“

### PrzykÅ‚ad 4: Analiza algorytmu z warunkami

**Kod:**
```java
int find(int[] array, int target) {
    for (int i = 0; i < array.length; i++) {
        if (array[i] == target) {
            return i;  // Znaleziono - koÅ„czymy
        }
    }
    return -1;  // Nie znaleziono
}
```

**Analiza przypadkÃ³w:**

**Najlepszy przypadek:**
- Element na pierwszej pozycji
- Operacje: 1 porÃ³wnanie + 1 return = 2
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(1)

**Najgorszy przypadek:**
- Element na ostatniej pozycji lub brak elementu
- Operacje: n porÃ³wnaÅ„ + 1 return = n + 1
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(n)

**PrzeciÄ™tny przypadek:**
- Element w Å›rodku
- Operacje: n/2 porÃ³wnaÅ„ + 1 return â‰ˆ n/2
- **ZÅ‚oÅ¼onoÅ›Ä‡:** O(n)

**W praktyce:** UÅ¼ywamy O(n) â€” najgorszy przypadek

---

## 15) Ä†wiczenia do samodzielnego rozwiÄ…zania

### Ä†wiczenie 1: Analiza prostej pÄ™tli
```java
void printArray(int[] array) {
    for (int i = 0; i < array.length; i++) {
        System.out.println(array[i]);
    }
}
```
**Pytanie:** Jaka jest zÅ‚oÅ¼onoÅ›Ä‡ czasowa? OdpowiedÅº: O(n)

### Ä†wiczenie 2: Analiza zagnieÅ¼dÅ¼onych pÄ™tli
```java
void printMatrix(int[][] matrix) {
    for (int i = 0; i < matrix.length; i++) {
        for (int j = 0; j < matrix[i].length; j++) {
            System.out.print(matrix[i][j] + " ");
        }
        System.out.println();
    }
}
```
**Pytanie:** Jaka jest zÅ‚oÅ¼onoÅ›Ä‡ czasowa? 
**OdpowiedÅº:** O(n Ã— m), gdzie n = liczba wierszy, m = liczba kolumn. JeÅ›li n = m, to O(nÂ²)

### Ä†wiczenie 3: Analiza z warunkiem
```java
boolean contains(int[] array, int target) {
    for (int i = 0; i < array.length; i++) {
        if (array[i] == target) {
            return true;
        }
    }
    return false;
}
```
**Pytanie:** Jaka jest zÅ‚oÅ¼onoÅ›Ä‡ w najlepszym, przeciÄ™tnym i najgorszym przypadku?
**OdpowiedÅº:** 
- Najlepszy: O(1) â€” element na pierwszej pozycji
- PrzeciÄ™tny: O(n) â€” element w Å›rodku
- Najgorszy: O(n) â€” element na koÅ„cu lub brak

### Ä†wiczenie 4: Analiza rekurencji
```java
int power(int base, int exp) {
    if (exp == 0) return 1;
    return base * power(base, exp - 1);
}
```
**Pytanie:** Jaka jest zÅ‚oÅ¼onoÅ›Ä‡ czasowa?
**OdpowiedÅº:** O(exp) â€” liczba wywoÅ‚aÅ„ rekurencyjnych = exp

### Ä†wiczenie 5: Analiza zÅ‚oÅ¼onoÅ›ci pamiÄ™ciowej
```java
int[] copyArray(int[] original) {
    int[] copy = new int[original.length];
    for (int i = 0; i < original.length; i++) {
        copy[i] = original[i];
    }
    return copy;
}
```
**Pytanie:** Jaka jest zÅ‚oÅ¼onoÅ›Ä‡ czasowa i pamiÄ™ciowa?
**OdpowiedÅº:** 
- Czasowa: O(n) â€” n iteracji
- PamiÄ™ciowa: O(n) â€” nowa tablica rozmiaru n

